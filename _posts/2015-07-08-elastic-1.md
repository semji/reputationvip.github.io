---
layout: post
author: quentin_fayet
title: "Elastic"
excerpt: "Elastic is a full-text search engine based on Apache Lucene"
modified: 2015-07-08
tags: [gitlab, git]
comments: true
image:
  feature: bandeau-gitlab.jpg
  credit: Alban Pommeret
  creditlink: http://reputationvip.io
---

# ELASTIC

## ROADMAP

This article is the first of many to come about Elastic. Elastic is a vast and amazing technology, and we could write thousands of lines about it.

So first, let me introduce the roadmap we'll follow all along these articles :

1. A smooth introduction to Elastic
2. Theorical approach : What's under the hood of Elastic ?
3. Installation and configuration of Elastic
4. Querying : Search, insert, and so on
5. Introduction to additional tools

## How to read these articles ?

Before we dive in Elastic head first, let me tell you how I organized these articles.

#### The articles 
First of all, all along these articles, i'll guide you through the understanding of Elastic. Each part of the articles will provide you theorical explanations, as well as examples.

#### The Virtual Machine

Available here : [https://github.com/quentinfayet/elasticsearch](https://github.com/quentinfayet/elasticsearch)

I know how difficult it could be to run someone else's example and code. So, I decided to provide a Vagrant environement, which will run for you a virtual machine, all set with
the needed environements and a simple Elastic cluster.
To make it run, first make sure you've installed Vagrant and VirtualBox.
Then, go to the "simple_cluster" folder and run "vagrant up" command.

## A smooth introduction to Elastic

### A bit of history

The story of Elastic started in 2004, when Shay Banon (founder of [Compass Project](https://en.wikipedia.org/wiki/Compass_Project)) thought about the third version of Compass.
The need then was to create a scalable search engine. Shay Banon decided to build a whole new project from the ground, using a common JSON and HTTP interface (building a REST API),
making it suitable for other programming languages than Java.
The first version of Elastic has been released in 2010.

Elastic is based on [Apache Lucene](https://lucene.apache.org/), and open source information retrieval library, also written in Java by Doug Cutting, supported by the Apache Software Foundation.

Also, Elastic is distributed, which means that **it can be divided into shards**, spread on a cluster of servers.

### Specific Vocabulary

In order for you to understand the rest of these articles, we'll need to speak the same language. That's why I give you here the base vocabulary used when talking about Elastic :

#### Document
The **Document** os the main data carrier of Elastic, used for indexing and searching. It is composed of **fields containing data**, retrieved by Apache Lucene.

#### Field
The **Field** refers as a part of a **Document**, composed of **a name and a value**.

#### Term
The **Term** is the unit of search. It represents **a word from the text**.

#### Token
The **Token** is **an occurence of a Term in a text field**. It is composed of **the Term, and its start and end offset**.

## Theorical approach : What's under the hood of Elastic ?

In this part, I'll talk about the main concepts that run Elastic, about Apache Lucene and the full-text research. I'll also give you an overview of data analysis, and how it is performed
by Elastic and Apache Lucene. Finally, i'll talk a bit about the architecture Elastic is based on.

### Inverted Index

Apache Lucene stores data into a structure called the **inverted index**. Instead of classical "relational" way, the **inverted index** maps **Terms** to **Documents**. It is **term-oriented**,
instead of being **document-oriented** (like a classical document based database would be).

More than words, let me give you an example.

Given these 3 documents (simple text lines) :

- Document <1> : ReputationVIP digital fortress
- Document <2> : ReputationVIP likes Elastic
- Document <3> : Elastic Cookbook

The resulting **inverted index mapping** would be :

Terms         | Occurences | Documents |
--------------|:----------:|---------- |
ReputationVIP | 2          | <1>, <2>  |
digital       | 1          | <1>       |
fortress      | 1          | <1>       |
Elastic       | 2          | <1>, <2>  |

### Segment

Index can be really big. So, Apache Lucene divides them into **Segments**
A **Segment** is only write once, and red many times. This means **segments can't be updated**.
Informations about deleted documents are written into separate files, since segments can't be updated.

#### Segments Merge

In order to improve performances, Apache Lucene can decide to proceed a **segment merge**.
Small segments are merged into bigger ones. **This can demands a lot of I/O**.
At that time, data are re-written into a new, bigger segment, and they might be updated (i.e deleted documents).
It's faster to search in one big segment, rather than in several small ones.

### Input Data Analysis

**Input Data Analysis (IDA)** defines the process that transforms input raw data into indexed data.
The **Analyzer** is in charge of this process. **Different analyzers can be applied to different fields**

#### Character Mapper
The **Character Mapper** stands to clean text, removing things like HTML tags, ...

#### Tokenizer
Apache Lucene's **Tokenizer** splits raw text into **tokens** (terms with position in the text & length).
The result is called **Token Stream** (stream of tokens which are going to be processed one by one by the **filters**).

#### Filters

**Filters** are applied on each token of the token stream.
I.E : **Lowercase filter** (all tokens are lowercased), **Synonyms filter** (applies basic synonym rules to tokens), ...
** Filters are processed one after another**

![Input Data Analysis](/images/elastic/input-data-analysis.png)

### Query Analysis

Now, it's time to have a look at how Apache Lucene can analyze submitted queries.

Let's say the query would be *"ReputationVIP"*

There is two ways Apache Lucene would analyze it:

- The first one, with the **Query Analyzer** turned on (based on **standard analyze**) ; the search would be performed both on *Reputation* and *VIP*, considered as two distinct **terms**
- The second one, without the **Query Analyzer** ; the search would be performed on *"ReputationVIP"* as a single **term**.

### Versioning

An important feature of Elastic is the **versioning**. When a document is added, updated or deleted, the version number is incremented. This process is known as **versioning**.
It allows Elastic to perform **optimistic concurrency control**

The **optimistic concurrency control (OCC)** assumes that frequently, multiple transactions car be performed. Each of them need to not to interfer with each other. When executing the
transaction, the data resources aren't locked. Before committing the transactions, it verifies that the data hasn't been modified by another transaction (using the version number). If so,
the transaction rolls back, and restarts.

### Architecture : Nodes & Clusters

Elastic is organized in **clusters**, composed of **nodes**.

A **node** is a **single instance of Elastic server**.

A **cluster** is a **group of nodes** working together as a single entity, with a **master** and several **slaves**. Clustering nodes achieves **fault tolerance**, **high availability** and allows
**large set of data**.

![Elastic Cluster](/images/elastic/cluster.png)

### Architecture : Shards

Nodes may be limited (RAM, I/O, Processing power, ...), and may not be able to answer queries fast enough.
So, each node can have **sards**
**Shards** can be placed on different servers, and data are spread among them.
To answer a query, a node may then query each shard and then, merge the results in a single answer.
**Shards** can also **speed up indexing**.
When a node is added to the cluster, shards are **dynamically re-allocated**

![Elastic Cluster](/images/elastic/shard.png)


